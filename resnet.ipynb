{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from xml.dom import HierarchyRequestErr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import shutil\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.utils.data.dataset' from '/Users/jayshih/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/utils/data/dataset.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class OxfordPetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_list, num_class, file_root, mode, transform=None):\n",
    "        data_dic = {str(num):[] for num in range(num_class)}\n",
    "\n",
    "        images = []\n",
    "        labels = open(data_list).readlines()\n",
    "        for line in labels:\n",
    "            items = line.strip('\\n').split()\n",
    "            img_name = items[0]\n",
    "            label = str(int(items[1]) - 1)\n",
    "\n",
    "            if int(label) > 23:\n",
    "              continue\n",
    "\n",
    "            data_dic[label].append(img_name)\n",
    "\n",
    "        for cls in range(num_class):\n",
    "            file_list = data_dic[str(cls)]\n",
    "            file_num = len(file_list)\n",
    "            imgs_list = [(file_root + file_list[i] + '.jpg', cls) for i in range(file_num)]\n",
    "            images = images + imgs_list\n",
    "\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name, label = self.images[index]\n",
    "        assert os.path.exists(img_name) == True\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return (img, label) if label is not None else img\n",
    "\n",
    "\n",
    "    # check all the images column length\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "def OxfordPet_dataloader(file_root, data_batch, train_data_list, val_data_list, num_class, img_size):\n",
    "\n",
    "\n",
    "    data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        #transforms.RandomResizedCrop(224, scale=(0.9,1.0)),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "        transforms.RandomRotation(degrees=5),\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    }\n",
    "\n",
    "    train_set = OxfordPetDataset(train_data_list, num_class, file_root, 'train', data_transforms['train'])\n",
    "    val_set = OxfordPetDataset(val_data_list, num_class,file_root, 'val',data_transforms['val'])\n",
    "\n",
    "\n",
    "    image_datasets = {'train': train_set , 'val': val_set }\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=data_batch, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "    return {'dataloaders':dataloaders, 'dataset_sizes':dataset_sizes}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, dataloaders, dataset_sizes, device, num_class, save_model_flag=False ):\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                print('start training!')\n",
    "                since_training = time.time()\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluation mode\n",
    "                print('start evaluation!')\n",
    "                since_val = time.time()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                final_train_acc = epoch_acc\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                epoch_on_best_acc = epoch\n",
    "\n",
    "            if phase == 'val':\n",
    "                final_val_acc = epoch_acc\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} best_acc: {:.4f}'.format(phase, epoch_loss, epoch_acc, best_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                time_elapsed = time.time() - since_training\n",
    "                time_elapsed_mins = time_elapsed // 60\n",
    "                #print('Training a epoch for {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            else:\n",
    "                time_elapsed = time.time() - since_val\n",
    "                time_elapsed_mins = time_elapsed // 60\n",
    "                #print('Validating a epoch for {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "    return {'final epoch train accuracy': final_train_acc.cpu().detach().numpy(), 'final epoch val accuracy': final_val_acc.cpu().detach().numpy(),\\\n",
    "     'highest val accuracy': best_acc.cpu().detach().numpy(), 'highest val accuracy epoch': epoch_on_best_acc, 'training time in mins': time_elapsed_mins}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "from decimal import Decimal\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "last_highest_val_accuracy = 0\n",
    "\n",
    "# check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('torch.cuda.is_available()={}'.format(torch.cuda.is_available()))\n",
    "\n",
    "\n",
    "\n",
    "if In_this_space_flag == True:\n",
    "  ## version 1: download file\n",
    "  # data folder\n",
    "  VOC_root_dir = \"/content/YOLO_data_model/\"\n",
    "  train_data_list = '/content/oxford-iiit-pet/file_train_list.txt'\n",
    "  val_data_list = '/content/oxford-iiit-pet/file_val_list.txt'\n",
    "  file_root = '/content/oxford-iiit-pet/images/'\n",
    "else:\n",
    "  ## version 2: access the folder in your google drive\n",
    "  train_data_list = '/content/drive/My Drive/oxford-iiit-pet/file_train_list.txt'\n",
    "  val_data_list = '/content/drive/My Drive/oxford-iiit-pet/file_val_list.txt'\n",
    "  file_root = '/content/drive/My Drive/oxford-iiit-pet/images/'\n",
    "\n",
    "\n",
    "\n",
    "num_class = 24#37\n",
    "img_size = 224\n",
    "\n",
    "num_epochs = 10\n",
    "lr = 0.0002\n",
    "num_batch = 12\n",
    "\n",
    "## 2. data preparation\n",
    "data_dic = OxfordPet_dataloader(file_root, num_batch, train_data_list, val_data_list, num_class, img_size)\n",
    "\n",
    "## 3. define model: the model will be downloaded to a temp folder\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "## 4. some surgery for the pretrained model, e.g., alexnet\n",
    "model_ft.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 2048), #256 * 6 * 6\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, 2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, num_class))\n",
    "\n",
    "#print(model_ft)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "## 5. define criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "## 6. define solver\n",
    "#optimizer = optim.SGD(model_ft.parameters(), lr=cfg['lr'], momentum=cfg['momentum'], weight_decay=0.0001)\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "## 7. define learning rate decay policy: step size & gamma\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "## 8. training the defined model for the designated epochs\n",
    "result_dic = train_model(model_ft, criterion, optimizer, exp_lr_scheduler, num_epochs=num_epochs, dataloaders = data_dic['dataloaders']\\\n",
    ", dataset_sizes = data_dic['dataset_sizes'], device = device, num_class=num_class)\n",
    "\n",
    "highest_val_accuracy = result_dic['highest val accuracy'].round(4)\n",
    "\n",
    "print('In {} epochs, highest val accuracy={} is achieved at epoch-{}'.format(num_epochs, highest_val_accuracy, result_dic['highest val accuracy epoch'] ) )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
